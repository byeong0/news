---
layout: post
title: "2025-12-29 AI 뉴스"
date: 2025-12-29 16:08:31 +0900
categories: news gemini
---

## OpenAI, '준비성 책임자(Head of Preparedness)' 채용 공고

<!-- Broken Image Removed: OpenAI 로고 -->
[The Guardian](https://www.theguardian.com/technology/2025/dec/29/sam-altman-launches-job-search-to-fill-critical-role-to-protect-against-ais-harms) - 발행일: 2025-12-29

### 요약
- 샘 알트만(Sam Altman)이 AI의 잠재적 위험에 대비하기 위한 '준비성 책임자(Head of Preparedness)' 채용을 시작했습니다.
- 해당 직책은 연봉 55만 5천 달러(약 7억 8천만 원) 규모로, AI가 인간의 정신 건강, 사이버 보안, 생물학적 무기 등에 미칠 수 있는 위협을 방어하는 역할을 맡습니다.
- 알트만은 이 역할이 "매우 스트레스가 많은 직업"이 될 것이라며, AI가 스스로 학습하여 인류에게 해를 끼칠 가능성까지 대비해야 한다고 언급했습니다.

### 주요 내용 및 시사점
- **기술적 의미**: AI 모델이 고도화됨에 따라 발생할 수 있는 '프론티어 리스크(Frontier Risks)'를 사전에 식별하고 완화하는 기술적 체계의 중요성이 강조되고 있습니다.
- **산업적 영향**: 주요 AI 기업들이 안전성 확보를 위한 전담 조직과 고위 임원직을 신설하는 추세가 가속화될 것으로 보입니다.
- **향후 전망**: AI 안전성에 대한 기업의 책임론이 강화되면서, 향후 규제 준수 및 리스크 관리가 AI 개발의 핵심 요소로 자리 잡을 것입니다.

---

## 중국, '인간 유사 AI(Human-like AI)'에 대한 규제 초안 발표

<!-- Broken Image Removed: AI 규제 관련 이미지 -->
[Insurance Journal](https://www.insurancejournal.com/news/international/2025/12/29/753682.htm) - 발행일: 2025-12-29

### 요약
- 중국 국가사이버정보판공실(CAC)이 인간과 유사하게 행동하는 AI 시스템에 대한 새로운 규제 초안을 발표했습니다.
- 서비스 제공자는 AI가 윤리적이고 안전하며 투명하게 운영되도록 보장해야 하며, 사용자가 AI와 대화하고 있음을 명확히 알 수 있도록 주기적으로 고지해야 합니다.
- 특히 100만 명 이상의 등록 사용자 또는 10만 명 이상의 월간 활성 사용자를 보유한 서비스는 보안 평가 보고서를 제출해야 합니다.

### 주요 내용 및 시사점
- **기술적 의미**: AI의 '의인화' 기능에 대한 기술적 제동 장치가 마련되며, 사용자가 AI 의존도에 빠지지 않도록 하는 알림 시스템 구현이 요구됩니다.
- **산업적 영향**: 중국 내 AI 서비스 기업들은 엄격한 윤리 심사와 보안 평가를 통과해야 하므로, 개발 및 배포 과정에서의 컴플라이언스 비용이 증가할 것입니다.
- **향후 전망**: 2026년 1월 25일까지 공개 의견 수렴을 거친 후, 해당 규제는 중국 AI 산업의 표준으로 자리 잡을 예정입니다.

---

## 카자흐스탄, EU에 이어 세계 두 번째로 독자적인 'AI 법' 채택

<!-- Broken Image Removed: 카자흐스탄 의회 -->
[The Astana Times](https://astanatimes.com/2025/12/kazakh-parliament-adopts-100-laws-in-2025-introduces-ai-regulation/) - 발행일: 2025-12-29

### 요약
- 카자흐스탄 의회가 2025년 주요 성과 중 하나로 독자적인 '인공지능법(Law on Artificial Intelligence)' 채택을 발표했습니다.
- 이는 유럽연합(EU)의 AI 법(EU AI Act)에 이어 전 세계에서 두 번째로 제정된 AI 전용 법률입니다.
- 해당 법안은 AI 기술 개발을 지원하는 동시에 안전한 사용 환경을 조성하기 위한 법적 기반을 마련하는 데 중점을 두고 있습니다.

### 주요 내용 및 시사점
- **기술적 의미**: 국가 차원에서 AI 기술의 정의와 허용 범위를 명문화함으로써, 기술 개발의 불확실성을 줄이고 표준화를 유도합니다.
- **산업적 영향**: 중앙아시아 지역에서 AI 기술 도입과 투자가 활성화될 수 있는 법적 토대가 마련되었으며, 글로벌 AI 규제 흐름에 동참하는 사례가 되었습니다.
- **향후 전망**: 다른 국가들도 EU와 카자흐스탄의 사례를 참고하여 자국 실정에 맞는 AI 규제 법안 도입을 서두를 것으로 예상됩니다.

---

## MIT와 리커전(Recursion), 신약 개발 가속화하는 AI 모델 'Boltz-2' 공개

<!-- Broken Image Removed: Bio-IT World 로고 -->
[Bio-IT World](https://www.bio-itworld.com/news/2025/12/29/top-stories-of-2025-ai-for-research-innovative-practices-digital-twins) - 발행일: 2025-12-29

### 요약
- MIT 연구진과 바이오 기업 리커전(Recursion)이 단백질 구조 예측 및 결합 친화도(Binding Affinity)를 예측하는 AI 모델 'Boltz-2'를 발표했습니다.
- 이 모델은 단일 GPU로 단 20초 만에 약물 후보 물질이 표적 단백질에 얼마나 강력하게 결합하는지 예측할 수 있습니다.
- Boltz-2는 상업적 및 비상업적 용도 모두를 위해 MIT 라이선스로 공개되었습니다.

### 주요 내용 및 시사점
- **기술적 의미**: 기존 모델 대비 연산 속도와 정확도를 획기적으로 개선하여, 신약 개발 초기 단계의 효율성을 극대화했습니다.
- **산업적 영향**: 제약 바이오 산업에서 AI 활용이 필수적인 요소로 자리 잡으며, 신약 개발 기간 단축 및 비용 절감 효과가 기대됩니다.
- **향후 전망**: 오픈 소스로 공개된 만큼 전 세계 연구자들이 이를 활용하여 다양한 질병 치료제 개발에 속도를 낼 것으로 보입니다.

---

## 러시아와 중국, AI 및 항공 전자 분야 협력 강화

<!-- Broken Image Removed: 러시아 중국 국기 -->
[Prensa Latina](https://www.plenglish.com/news/2025/12/29/russia-and-china-want-to-cooperate-in-ai-and-aviation-electronics/) - 발행일: 2025-12-29

### 요약
- 장한후이(Zhang Hanhui) 주러시아 중국 대사는 중국이 러시아와 AI 기술 및 항공 전자 시스템 개발 협력을 심화할 계획이라고 밝혔습니다.
- 양국은 반도체 소재, 특수 마이크로칩 설계, 첨단 제조 공정 등 하이테크 분야에서의 상호 작용을 강화하기로 했습니다.
- 중국은 AI 분야의 글로벌 협력 기구 창설에 러시아의 적극적인 참여를 환영한다고 덧붙였습니다.

### 주요 내용 및 시사점
- **기술적 의미**: 서방의 제재 속에서 중-러 양국이 자체적인 기술 생태계를 구축하고 공급망 안정성을 확보하려는 시도입니다.
- **산업적 영향**: 글로벌 AI 기술 패권 경쟁이 '서방 진영' 대 '중-러 진영'으로 더욱 뚜렷하게 양분될 가능성이 있습니다.
- **향후 전망**: 양국의 협력은 군사 및 민간 항공 분야의 AI 도입을 가속화하며, 국제 기술 표준 경쟁에도 영향을 미칠 것입니다.

---

## 2025년 AI 보안 위협 Top 5 및 '섀도우 AI' 경고

<!-- Broken Image Removed: 보안 관련 이미지 -->
[CSO Online](https://www.csoonline.com/article/3646282/top-5-real-world-ai-security-threats-revealed-in-2025.html) - 발행일: 2025-12-29

### 요약
- 2025년 주요 AI 보안 위협으로 '섀도우 AI(Shadow AI)', 취약한 AI 도구, 프롬프트 인젝션 공격 등이 선정되었습니다.
- 보고서에 따르면 조직의 84%가 클라우드에서 AI 도구를 사용 중이며, 그중 62%는 환경 내에 최소 하나 이상의 취약한 AI 패키지를 보유하고 있습니다.
- 깃허브 코파일럿(GitHub Copilot), 챗GPT(ChatGPT) 등 주요 AI 플랫폼에서 민감한 데이터 유출을 유발할 수 있는 공격 사례가 확인되었습니다.

### 주요 내용 및 시사점
- **기술적 의미**: AI 모델 자체의 보안 취약점뿐만 아니라, 이를 통합하는 클라우드 환경의 설정 오류가 주요 위협으로 부상했습니다.
- **산업적 영향**: 기업 보안 팀은 승인되지 않은 AI 도구 사용(섀도우 AI)을 통제하고, AI 공급망 보안을 강화해야 하는 과제에 직면했습니다.
- **향후 전망**: AI 보안 솔루션 시장이 급성장할 것이며, 기업들은 AI 도입 시 기능성보다 보안성을 우선순위에 두게 될 것입니다.